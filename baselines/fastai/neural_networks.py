# -*- coding: utf-8 -*-

"""Neural Networks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E5F6Xs3HQxB_5PzFyTCry11JvhGTtg3U
"""

import pandas as pd
import numpy as np
import math
from scipy import linalg
from fastai.collab import *
import tensorflow as tf

"""# Read Cleaned Data"""

data_raw = pd.read_csv("data_train_clean.csv")
data_raw.shape

data_sub = pd.read_csv("sampleSubmission_clean.csv")
data_sub.shape

data = CollabDataBunch.from_df(data_raw, seed=42, valid_pct=0.2, user_name='User', item_name='Movie',
                               rating_name='Prediction', test=data_sub)

data.show_batch()

learn = collab_learner(data, use_nn = True, emb_szs={'User':30,'Movie':80} , layers=[200,128,64,16], y_range=(1, 5))

learn.lr_find() # find learning rate
learn.recorder.plot(suggestion=True) # plot learning rate graph
min_grad_lr = learn.recorder.min_grad_lr

learn.fit_one_cycle(5,0.0001)
learn.fit_one_cycle(2,min_grad_lr)

#learn.fit_one_cycle(1,0.00001)

#learn.fit_one_cycle(5,0.0001)

#learn.fit_one_cycle(1,0.00001)

#learn.fit_one_cycle(1,0.00001)

#learn.fit_one_cycle(1,0.00001)

# preds = learn.get_preds(DatasetType.Test)

# preds_all = (preds[0].T)[0].numpy()
# data_sub["Prediction"] = pd.Series(preds_all)
# data_sub.head()

# data_sub["Id"] = data_sub.apply(lambda x:"r"+str(int(x["User"]))+"_c"+str(int(x["Movie"])),axis=1)

# data_sub.head()

# print(np.min(data_sub["Prediction"]))
# np.max(data_sub["Prediction"])

# data_sub[["Id","Prediction"]].to_csv("nn_200_new2.csv",index=False)
